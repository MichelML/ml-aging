{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction   \n",
    "\n",
    "The goal of this notebook is to describe my journey after almost a month of work competing on Kaggle's competition [_CellSignal: Disentangling biological signal from experimental noise in cellular images_](https://www.kaggle.com/c/recursion-cellular-image-classification/overview).   \n",
    "\n",
    "As I plan on continuing to compete after graduating from the nanodegree, this notebook will contain the following sections:   \n",
    "\n",
    "- The journey   \n",
    "- Upcoming attempts   \n",
    "- Reflexions   \n",
    "- Conclusion\n",
    "- Thanks\n",
    "\n",
    "\n",
    "# The journey\n",
    "\n",
    "### Technical limitations disclaimer\n",
    "\n",
    "Since I started this competition a month ago, after my proposal had been accepted, I ran into several issues preventing me to experiment all the things I wanted to before graduating.   \n",
    "\n",
    "First, I needed to upload the competition's data on FloydHub because this is where I have the most GPU credits, which is definitely needed for this competition. During this process, I corrupted the data and it took me a whole week to realize this was the problem. My models didn't want to train because of that, and the stacktrace and errors were not comprehensible. I was then back to square one after a week and a half of work.   \n",
    "\n",
    "I then tried a second time to upload the data on FloydHub, but for unknown reasons, this time it was crashing at the middle of the almost-24-hour-long uploading process. I lost about three days trying to upload the data, to finally give up.   \n",
    "\n",
    "This is at this moment that I started to work directly through Kaggle's kernels. However, Kaggle's kernels have limited resources and do not allow to train more complex models such as ResNet-152 or any Densenet - which appear to be one of the key in obtaining superior scores according to some of the competition's discussions. Furthermore, kernels on Kaggle have a 9 hours computing time limit. This forces you to divide work across multiple kernels because the time to train models for this competition is quite long - 1 hour for the base model, 5+ hours for the ResNet-50, and most likely way more for more complex models with a lower learning rate (because more epochs before convergence). Also, since [some discussions vent the merit of adopting a two-step model approach](https://www.kaggle.com/c/recursion-cellular-image-classification/discussion/100414#latest-586901) (a step to train the model on all the cell images, and a second step to train models on one of the four cell types (HEPG2, HUVEC, RPE, U2OS), training time can be very long. \n",
    "\n",
    "\n",
    "\n",
    "Actions will be taken to solve all of those technical limitations in the upcoming weeks, but I couldn't have known these limitations ahead of time as a first time Kaggler. This will be discussed in the _Upcoming attempts_ section.\n",
    "\n",
    "\n",
    "### Base Model\n",
    "\n",
    "\n",
    "### ResNet-50   \n",
    "\n",
    "### ResNet-50 (step 2)\n",
    "\n",
    "### Current score\n",
    "\n",
    "After reading a lot of [papers](https://github.com/MichelML/ml-cellsignal/tree/master/information), [blog posts](https://github.com/MichelML/ml-cellsignal/tree/master/information), [kernels](https://www.kaggle.com/c/recursion-cellular-image-classification/kernels), and [discussions](https://www.kaggle.com/c/recursion-cellular-image-classification/discussion), and trying various model architectures (which I'll talk about later), my current best solution for this 1108-class classification problems is `12.5%` based on [the model weights of the 12th epoch](https://github.com/MichelML/ml-cellsignal/tree/master/models). My best LB score is actually `~18%` but it comes from a public Kaggle kernel I ran, which was provided by another participant. \n",
    "\n",
    "Although much improvement remains to be made, a score of `12.5%` is actually way better than chance since we have 1108 classes. It allows me to rank in the top 25% of the competition thus far. An accuracy score reflecting chance would be 1/1108, which is equivalent to ~0.09%.   \n",
    "\n",
    "### Comparative discussion againt the proposal\n",
    "\n",
    "# Upcoming attempts   \n",
    "\n",
    "# Reflexion   \n",
    "\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
